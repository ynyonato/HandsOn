{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8QiSOnq+wQbN5XCK1mmHg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ynyonato/HandsOn/blob/updates/ia_me_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import des librairies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "25EEnFwEV6k6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Télécharger stopwords et autres ressources NLTK si besoin\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "yoiffI47V9UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement des données (ici on suppose que le fichier csv est uploadé dans Colab)\n",
        "df = pd.read_csv('ia-me/suivi_activites.csv', sep=';', encoding='latin-1', quotechar='\"')\n",
        "\n",
        "# Apercu\n",
        "print(df.columns)\n",
        "print(df.head())\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGIlz8KNWAGz",
        "outputId": "e4b162de-5add-406d-d021-3da5a2ff6c89"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ID_Activite', 'Date', 'Type_Activite', 'Nombre_Participants',\n",
            "       'Localisation', 'Feedback', 'Resultat_Attendu'],\n",
            "      dtype='object')\n",
            "   ID_Activite        Date             Type_Activite  Nombre_Participants  \\\n",
            "0            1  05/01/2025  Distribution de matériel                   25   \n",
            "1            2  10/01/2025         Atelier formation                   15   \n",
            "2            3  15/01/2025          Suivi individuel                   10   \n",
            "3            4  20/01/2025  Distribution de matériel                   30   \n",
            "4            5  25/01/2025         Atelier formation                   20   \n",
            "\n",
            "  Localisation                                      Feedback Resultat_Attendu  \n",
            "0      Ville A    Les bénéficiaires ont apprécié la rapidité         Réussite  \n",
            "1      Ville B                Manque de matériel pédagogique           Risque  \n",
            "2      Ville A  Très bonne interaction avec les participants         Réussite  \n",
            "3      Ville C  Certains participants sont arrivés en retard         Réussite  \n",
            "4      Ville B                  Besoin de prolonger la durée         Réussite  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50 entries, 0 to 49\n",
            "Data columns (total 7 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   ID_Activite          50 non-null     int64 \n",
            " 1   Date                 50 non-null     object\n",
            " 2   Type_Activite        50 non-null     object\n",
            " 3   Nombre_Participants  50 non-null     int64 \n",
            " 4   Localisation         50 non-null     object\n",
            " 5   Feedback             50 non-null     object\n",
            " 6   Resultat_Attendu     50 non-null     object\n",
            "dtypes: int64(2), object(5)\n",
            "memory usage: 2.9+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversion des données de la colonne Date en type date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y', errors='coerce')\n",
        "\n",
        "# Traitement des valeurs manquantes (voir nombre)\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Vérification des doublons\n",
        "print(df.duplicated().sum())\n",
        "\n",
        "# Suppression des doublons\n",
        "df = df.drop_duplicates()"
      ],
      "metadata": {
        "id": "Nc_kPVO218qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nettoyage basique du texte (feedback)\n",
        "def clean_text(text):\n",
        "    if pd.isnull(text):\n",
        "        return \"\"\n",
        "    # Mise en minuscule\n",
        "    text = text.lower()\n",
        "    # Suppression ponctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Suppression chiffres\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    # Suppression des stopwords\n",
        "    text = ' '.join([mot for mot in text.split() if mot not in stop_words])\n",
        "    return text\n",
        "\n",
        "df['Feedback_clean'] = df['Feedback'].apply(clean_text)\n",
        "\n",
        "# Vérification si le traitement s'est bien déroulé et que la colonne traitée n'est pas vide\n",
        "print(df['Feedback_clean'].head())"
      ],
      "metadata": {
        "id": "T2kKf7I7WEc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "À ce stade :\n",
        "*   La colonne Date est bien formatée\n",
        "*   Les doublons sont supprimés\n",
        "*   Élément de liste\n",
        "*   Les Feedback sont nettoyés et une nouvelle colonne Feedback_clean est créée\n",
        "*   Les champs manquants sont visibles pour traitement ultérieurÉlément de liste\n",
        "\n"
      ],
      "metadata": {
        "id": "aonw3a4z4LKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ÉTAPE 2 : ANALYSE EXPLORATOIRE DE BASE (EDA)\n",
        "\n",
        "# Aperçu des statistiques descriptives des colonnes numériques\n",
        "print(\"Résumé statistique des colonnes numériques :\")\n",
        "print(df.describe())  # Affiche count, mean, std, min, 25%, 50%, 75%, max pour les colonnes numériques\n",
        "\n",
        "# Nombre de valeurs uniques par colonne\n",
        "print(\"\\nNombre de valeurs uniques par colonne :\")\n",
        "print(df.nunique())  # Permet d'identifier les variables catégorielles ou constantes\n",
        "\n",
        "# Aperçu rapide des types de données\n",
        "print(\"\\nTypes de données dans le DataFrame :\")\n",
        "print(df.dtypes)  # Vérifie les types (object, int64, float64, etc.)\n",
        "\n",
        "# Vérification de la présence de valeurs manquantes\n",
        "print(\"\\nNombre de valeurs manquantes par colonne :\")\n",
        "print(df.isnull().sum())  # Pour détecter les colonnes incomplètes ou problématiques"
      ],
      "metadata": {
        "id": "5vVlYMy47i_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ÉTAPE 3 : NETTOYAGE ET PRÉPARATION DES DONNÉES\n",
        "\n",
        "# 1. Suppression des doublons\n",
        "df = df.drop_duplicates()\n",
        "print(\"✔️ Doublons supprimés.\")\n",
        "\n",
        "# 2. Suppression des colonnes inutiles (à adapter si tu identifies des colonnes non pertinentes)\n",
        "# Exemple : si une colonne 'ID' ou 'timestamp' est sans intérêt\n",
        "# df = df.drop(['NomDeLaColonne1', 'NomDeLaColonne2'], axis=1)\n",
        "\n",
        "# 3. Gestion des valeurs manquantes (ici on les supprime, on peut aussi les remplir si besoin)\n",
        "df = df.dropna()\n",
        "print(\"✔️ Lignes avec valeurs manquantes supprimées.\")\n",
        "\n",
        "# 4. Harmonisation des noms de colonnes (sans espaces, minuscules, underscores)\n",
        "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
        "print(\"✔️ Noms de colonnes nettoyés :\", df.columns.tolist())\n",
        "\n",
        "# 5. Conversion de colonnes en types appropriés (exemple : dates ou numériques)\n",
        "# Exemple : convertir une colonne 'date' en datetime\n",
        "# df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "\n",
        "# Exemple : convertir une colonne en numérique\n",
        "# df['revenu'] = pd.to_numeric(df['revenu'], errors='coerce')\n",
        "\n",
        "# 6. Affichage de l’état final du jeu de données\n",
        "print(\"\\n✔️ Données prêtes. Aperçu des premières lignes :\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "OxX-S1h-8xzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Étape 4 : Visualisation des données avec matplotlib et seaborn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configuration de base pour un style clair\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
        "\n",
        "# 1. Histogramme pour une variable numérique\n",
        "# Exemple : 'revenu' – à adapter selon tes colonnes\n",
        "# Remplace 'revenu' par le nom réel de ta colonne\n",
        "if 'revenu' in df.columns:\n",
        "    sns.histplot(data=df, x='revenu', kde=True, color='skyblue')\n",
        "    plt.title('Distribution des revenus')\n",
        "    plt.xlabel('Revenu')\n",
        "    plt.ylabel('Fréquence')\n",
        "    plt.show()\n",
        "\n",
        "# 2. Diagramme en barres pour une variable catégorielle\n",
        "# Exemple : 'produit'\n",
        "if 'produit' in df.columns:\n",
        "    sns.countplot(data=df, x='produit', palette='Set2')\n",
        "    plt.title('Nombre d\\'occurrences par produit')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.ylabel('Nombre')\n",
        "    plt.show()\n",
        "\n",
        "# 3. Boîte à moustaches (boxplot) pour voir les outliers\n",
        "# Exemple : 'revenu' par 'produit'\n",
        "if 'revenu' in df.columns and 'produit' in df.columns:\n",
        "    sns.boxplot(data=df, x='produit', y='revenu', palette='Set3')\n",
        "    plt.title('Répartition des revenus par produit')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "# 4. Matrice de corrélation (pour les variables numériques)\n",
        "corr_matrix = df.select_dtypes(include='number').corr()\n",
        "\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title('Matrice de corrélation')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TnozqwEB-FqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Étape 5 : Préparation des données pour le ML\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# 1. Sélection des colonnes pertinentes\n",
        "# À adapter selon tes colonnes — exemple ici\n",
        "colonnes_utiles = ['revenu', 'age', 'produit', 'sexe', 'achat']  # à modifier\n",
        "df_ml = df[colonnes_utiles].copy()\n",
        "\n",
        "# 2. Encodage des variables catégorielles\n",
        "# Exemple : encodage de 'produit' et 'sexe' si elles sont catégorielles\n",
        "cat_cols = df_ml.select_dtypes(include='object').columns\n",
        "\n",
        "# Utilisation de LabelEncoder pour transformer les catégories en nombres\n",
        "label_encoders = {}\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    df_ml[col] = le.fit_transform(df_ml[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# 3. Séparation X (features) et y (target)\n",
        "# Supposons que la colonne 'achat' est la cible (binaire : 0 ou 1)\n",
        "X = df_ml.drop('achat', axis=1)\n",
        "y = df_ml['achat']\n",
        "\n",
        "# 4. Séparation en ensemble d'entraînement et de test (80% / 20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 5. Standardisation des données numériques\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "T62wg0du89qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Étape 6 : Entraînement d’un modèle de Machine Learning\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# 1. Initialiser le modèle avec des hyperparamètres de base\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# 2. Entraînement du modèle sur l'ensemble d'entraînement\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 3. Prédiction sur les données de test\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# 4. Évaluation du modèle\n",
        "# a. Taux de bonne classification (accuracy)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy : {accuracy:.2%}\")\n",
        "\n",
        "# b. Matrice de confusion\n",
        "print(\"\\nMatrice de confusion :\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# c. Rapport de classification détaillé (précision, rappel, F1-score)\n",
        "print(\"\\nRapport de classification :\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "NtiwrOre_Mx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppression des stopwords\n",
        "stop_words = set(stopwords.words('french'))\n",
        "def remove_stopwords(text):\n",
        "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
        "\n",
        "df['Feedback_clean'] = df['Feedback_clean'].apply(remove_stopwords)"
      ],
      "metadata": {
        "id": "pIRmFCETWF16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if there are any non-empty strings after cleaning and stopword removal\n",
        "if df['Feedback_clean'].str.strip().eq('').all():\n",
        "    print(\"Erreur: Après nettoyage et suppression des mots vides, la colonne 'Feedback_clean' est vide. Impossible de créer un vocabulaire TF-IDF.\")\n",
        "    # Option 1: Print some raw feedback to understand why it's empty\n",
        "    print(\"\\nExemples de feedback originaux :\")\n",
        "    print(df['Feedback'].head())\n",
        "    # Option 2: You might need to revisit your cleaning steps or data source\n",
        "else:\n",
        "    vectorizer = TfidfVectorizer(max_features=20)\n",
        "    X = vectorizer.fit_transform(df['Feedback_clean'])\n",
        "    tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "    # Somme des TF-IDF par mot pour voir les plus importants\n",
        "    tfidf_sum = tfidf_df.sum().sort_values(ascending=False)\n",
        "    print(\"Top mots-clés TF-IDF :\")\n",
        "    print(tfidf_sum)"
      ],
      "metadata": {
        "id": "aXAFZrcUZlOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = vectorizer.fit_transform(df['Feedback_clean'])\n",
        "tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "l7c4Nxu2ZmfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Somme des TF-IDF par mot pour voir les plus importants\n",
        "tfidf_sum = tfidf_df.sum().sort_values(ascending=False)\n",
        "print(\"Top mots-clés TF-IDF :\")\n",
        "print(tfidf_sum)"
      ],
      "metadata": {
        "id": "HjrOp28zWMEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse de sentiment avec TextBlob (en français)\n",
        "# On utilise TextBlob directement ici, qui marche mieux en anglais, mais ça donnera un aperçu\n",
        "# Pour un vrai traitement en français, on pourrait utiliser d’autres libs (ex: HuggingFace)\n",
        "def sentiment_polarity(text):\n",
        "    return TextBlob(text).sentiment.polarity\n",
        "\n",
        "df['Sentiment'] = df['Feedback_clean'].apply(sentiment_polarity)"
      ],
      "metadata": {
        "id": "nkPB6HVNWSis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Catégorisation simple du sentiment\n",
        "def categorize_sentiment(score):\n",
        "    if score > 0.1:\n",
        "        return 'Positif'\n",
        "    elif score < -0.1:\n",
        "        return 'Négatif'\n",
        "    else:\n",
        "        return 'Neutre'\n",
        "\n",
        "df['Sentiment_cat'] = df['Sentiment'].apply(categorize_sentiment)"
      ],
      "metadata": {
        "id": "JW97AF1kWUFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Affichage des counts sentiment\n",
        "print(\"\\nRépartition des sentiments :\")\n",
        "print(df['Sentiment_cat'].value_counts())"
      ],
      "metadata": {
        "id": "0r-saN1yWX8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nuage de mots pour feedback global\n",
        "all_text = ' '.join(df['Feedback_clean'])\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title(\"Nuage de mots - Feedback\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qgmNExCFWcSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graphique des sentiments par type d'activité\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(data=df, x='Type_Activite', hue='Sentiment_cat')\n",
        "plt.title(\"Sentiments par Type d'Activité\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NH0nd_olWgMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Moyenne de sentiment par localisation\n",
        "sentiment_localisation = df.groupby('Localisation')['Sentiment'].mean().sort_values()\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sentiment_localisation.plot(kind='bar', color='skyblue')\n",
        "plt.title(\"Moyenne du sentiment par localisation\")\n",
        "plt.ylabel(\"Score moyen de sentiment\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_LS7bhpIWjDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Croisement nombre participants vs sentiment (boxplot)\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.boxplot(data=df, x='Sentiment_cat', y='Nombre_Participants')\n",
        "plt.title(\"Nombre de participants selon sentiment\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FWBOvNf3Wl3W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}